import pandas as pd
import os
from openpyxl.utils import get_column_letter

AUTO_CODE_START = 90000000  # Base for autogenerated codes

def clean_receipts(file_path):
    """
    Load and clean receipts data from Excel.
    Ensures required columns exist and normalizes data.
    Removes unnecessary columns and keeps original order.
    """
    df = pd.read_excel(file_path)
    df.columns = df.columns.str.strip()  # Clean headers

    # Required columns
    required = ["store", "location", "item", "price", "quantity", "date"]
    for col in required:
        if col not in df.columns:
            raise KeyError(f"Missing required column: {col}")

    # Optional column
    if "productCode" not in df.columns:
        df["productCode"] = None

    # Convert column types
    df["date"] = pd.to_datetime(df["date"], dayfirst=True, errors="coerce")
    df["price"] = pd.to_numeric(df["price"], errors="coerce")
    df["quantity"] = pd.to_numeric(df["quantity"], errors="coerce")

    # Drop rows missing critical info
    df = df.dropna(subset=["item", "date", "price", "quantity"])

    # Normalize item name
    df["item_clean"] = df["item"].str.strip().str.lower()

    # Compute total value
    df["total_value"] = df["price"] * df["quantity"]

    # Keep only necessary columns, preserving original order
    keep_cols = ["store", "location", "date", "price", "quantity", "productCode", "item_clean", "total_value"]
    df = df[keep_cols]

    return df



def create_lookup_table(df, lookup_path="item_lookup.xlsx"):
    """
    Build/update a stable lookup table for items.
    Ensures all store/item_clean combos have a stable productCode.
    """
    import os
    from openpyxl.utils import get_column_letter

    if os.path.exists(lookup_path):
        lookup_df = pd.read_excel(lookup_path, dtype={"productCode": "Int64"})
    else:
        lookup_df = pd.DataFrame(columns=["store", "item_clean", "productCode"])

    # Merge existing codes into df
    df = df.merge(
        lookup_df[["store", "item_clean", "productCode"]],
        on=["store", "item_clean"],
        how="left",
        suffixes=('', '_lookup')
    )

    df["productCode"] = df["productCode"].fillna(df["productCode_lookup"])
    df = df.drop(columns=[c for c in df.columns if c.endswith("_lookup")])

    updated_records = []

    for _, row in df.iterrows():
        store = str(row["store"]).strip()
        item_clean = str(row["item_clean"]).strip()

        # Assign existing or new code
        if pd.notna(row["productCode"]):
            code = int(row["productCode"])
        else:
            code = AUTO_CODE_START + (abs(hash(store + item_clean)) % 10000000)

        # Check if this store/item_clean already exists in lookup
        match = lookup_df[(lookup_df["store"] == store) & (lookup_df["item_clean"] == item_clean)]
        if match.empty or code not in match["productCode"].values:
            updated_records.append({
                "store": store,
                "item_clean": item_clean,
                "productCode": code
            })

        # Update df with code
        df.loc[row.name, "productCode"] = code

    # Merge new records
    if updated_records:
        lookup_df = pd.concat([lookup_df, pd.DataFrame(updated_records)], ignore_index=True)

    # Deduplicate by store+item_clean+productCode
    lookup_df = lookup_df.drop_duplicates(subset=["store", "item_clean", "productCode"])

    # Sort for readability
    lookup_df = lookup_df.sort_values(["store", "item_clean"]).reset_index(drop=True)

    # Save nicely
    with pd.ExcelWriter(lookup_path, engine="openpyxl") as writer:
        lookup_df.to_excel(writer, index=False, sheet_name="Lookup")
        worksheet = writer.sheets["Lookup"]
        for i, col in enumerate(lookup_df.columns, 1):
            max_len = max(lookup_df[col].astype(str).map(len).max(), len(col)) + 2
            worksheet.column_dimensions[get_column_letter(i)].width = max_len

    return lookup_df


def merge_codes_by_item_clean(df: pd.DataFrame, lookup_path: str = "item_lookup.xlsx") -> pd.DataFrame:
    """
    Fill missing df['productCode'] by matching df['item_clean'] to the lookup table.
    - No merge (so rows never reorder)
    - Only fills where productCode is NA
    - If multiple codes exist for the same item_clean in the lookup, uses the mode (most frequent),
      falling back to the first seen.
    """
    if not os.path.exists(lookup_path):
        # Nothing to fill from
        return df

    # Read lookup and normalize types
    lookup = pd.read_excel(lookup_path, dtype={"productCode": "Int64"}).copy()

    # Ensure normalized key exists in lookup
    lookup["item_clean"] = (
        lookup["item_clean"].astype(str).str.strip().str.lower()
    )

    # Build a stable mapping: item_clean -> preferred code
    def _prefer_code(series: pd.Series):
        # Use the most frequent code; if tie/none, take first
        m = series.mode(dropna=True)
        return m.iat[0] if not m.empty else series.dropna().iloc[0]

    code_map = (
        lookup.dropna(subset=["productCode"])
              .groupby("item_clean")["productCode"]
              .agg(_prefer_code)
    )

    # Ensure df has correct dtype and key normalized
    if "productCode" not in df.columns:
        df["productCode"] = pd.Series([pd.NA] * len(df), dtype="Int64")
    else:
        df["productCode"] = pd.to_numeric(df["productCode"], errors="coerce").astype("Int64")

    df["item_clean"] = df["item_clean"].astype(str).str.strip().str.lower()

    # Fill ONLY missing codes using the map (no reordering, no duplication)
    missing = df["productCode"].isna()
    df.loc[missing, "productCode"] = (
        df.loc[missing, "item_clean"].map(code_map).astype("Int64")
    )

    return df